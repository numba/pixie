{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demonstration of the PIXIE project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demonstration of the, currently at proof-of-concept stage, PIXIE (<b>P</b>ortable <b>I</b>nstructions e<b>X</b>changed <b>I</b>n <b>E</b>xecutable) project.\n",
    "\n",
    "<b>WARNING: This is a proof-of-concept technology demonstration only and not suitable for general use!</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the PIXIE project is to provide tools to create Ahead-Of-Time (AOT), but Just-In-Time (JIT) compiler \"friendly\", libraries that put their performance profile into the hands of the user.\n",
    "\n",
    "This demonstration includes:\n",
    "\n",
    "1. [Compiling some LLVM IR via PIXIE into a shared library.](#1.-Compiling-some-LLVM-IR-via-PIXIE-into-a-shared-library.)\n",
    "2. [Using PIXIE to make a shared library available as a Python C-Extension.](#2.-Using-PIXIE-to-make-a-shared-library-available-as-a-Python-C-Extension.)\n",
    "3. [Exploring the `__PIXIE__` dictionary in a PIXIE created C-Extension.](#3.-Exploring-the-__PIXIE__-dictionary-in-a-PIXIE-created-C-Extension.)\n",
    "4. [Calling functions from the `__PIXIE__` dictionary with Numba via `ctypes` and LLVM bitcode.](#4.-Calling-functions-from-the-__PIXIE__-dictionary-with-Numba-via-ctypes-and-LLVM-bitcode.)\n",
    "5. [Host (or other target) specialisation and automatic rewiring of the `__PIXIE__` dictionary.](#5.-Host-(or-other-target)-specialisation-and-automatic-rewiring-of-the-__PIXIE__-dictionary.)\n",
    "6. [Numba++'s Minimum Viable Product (MVP)](#6.-Numba++'s-Minimum-Viable-Product-(MVP))\n",
    "   1. [\"Blending\" input languages through AOT compiled modules. Example application, a \"custom\" solver.](#6A.-\"Blending\"-input-languages-through-AOT-compiled-modules.-Example-application,-a-\"custom\"-solver.)\n",
    "   2. [\"Blending\" performance through AOT compiled modules. Example application, a DAXPY-like function call.](#6B.-\"Blending\"-performance-through-AOT-compiled-modules.-Example-application,-a-DAXPY-like-function-call.)\n",
    "\n",
    "<b>NOTE: PIXIE and this demonstration currently target x86_64 CPUs running Linux operating systems. Other CPUs and operating systems will be supported in the future. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compiling some LLVM IR via PIXIE into a shared library.\n",
    "\n",
    "First, import some PIXIE compiler components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pixie import PIXIECompiler, TranslationUnit, ExportConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIXIE consumes LLVM intermediate representation (IR) (or LLVM bitcode) and operates on translation units, just like LLVM - where a translation unit is approximately a module or in e.g. clang/GCC compilation of C language code - where a translation unit is typically a \"file\". Create some LLVM IR as input source to put into a translation unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This LLVM IR is the equivalent to the C code:\n",
    "# void foo(double* a, double* b, double* out)\n",
    "# {\n",
    "#      *out = *a + *b;\n",
    "# }\n",
    "\n",
    "foo_double_double = \"\"\"\n",
    "define void @\"_Z3fooPdS_\"(double* %\".1\", double* %\".2\", double* %\".out\")\n",
    "{\n",
    "entry:\n",
    "    %.3 = load double, double * %.1\n",
    "    %.4 = load double, double * %.2\n",
    "    %\"res\" = fadd double %\".3\", %\".4\"\n",
    "    store double %\"res\", double * %\".out\"\n",
    "    ret void\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation units are stored into an iterable, this is synonymous to a command line invocation e.g.\n",
    "\n",
    "`$CC <translation unit 1>... <translation unit n>`\n",
    "\n",
    "Create an interable containing a translation unit holding the LLVM IR from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tus = [TranslationUnit(\"foo_double_double\" , foo_double_double),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next PIXIE needs to be informed about what is to be exported (i.e. which symbols are global), this is done via an export configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an export configuration object, the kwarg \"versioning_strategy\" is not used yet,\n",
    "# but will eventually inform how to create ISA specific versions of the code being compiled.\n",
    "export_config = ExportConfiguration(versioning_strategy='embed_dso')\n",
    "export_config.add_symbol(python_name=\"foo\", symbol_name=\"_Z3fooPdS_\", signature=\"void(double*, double*, double*)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now initialize a PIXIE compiler instance and call `.compile()` to compile the source into a shared library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pixie.cpus import x86\n",
    "\n",
    "# Create a compiler instance\n",
    "libfoo_compiler = PIXIECompiler(library_name='foo_library', # the name for the output shared library\n",
    "                                translation_units=tus, # translation units\n",
    "                                export_configuration=export_config, # export config\n",
    "                                baseline_cpu='nocona', # The \"baseline\" CPU, this is the CPU that the library itself will target\n",
    "                                baseline_features=x86.sse3, # feature set(s) that the library will target\n",
    "                                python_cext=False, # whether the output shared library should be a C-Extension\n",
    "                                output_dir='.',) # directory in which to put the shared library once it has been created\n",
    "\n",
    "# ... and compile the shared library\n",
    "libfoo_compiler.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All PIXIE is doing is using LLVM's MCJIT to create object files and then linking them with a native linker. The output is just a standard shared library (NOTE: there's a bug in the naming scheme at present that means the shared libraries end up with C-Extension-like names). Take a look at the shared library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!file foo_library.*so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shared library can be loaded with `ctypes` calls and then the symbol from the function defined in the LLVM IR above can be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ctypes import CDLL, byref, c_double, POINTER\n",
    "import os\n",
    "\n",
    "# Set up binding, load the library from the PWD\n",
    "dso = CDLL(os.path.join('.', libfoo_compiler._output_file))\n",
    "dso._Z3fooPdS_.argtypes = (POINTER(c_double),) * 3\n",
    "dso._Z3fooPdS_.restype = None\n",
    "\n",
    "# Stage call\n",
    "a = c_double(3)\n",
    "b = c_double(5)\n",
    "out = c_double(0)\n",
    "dso._Z3fooPdS_(*(byref(x) for x in (a, b, out)))\n",
    "print(f\"{a.value} + {b.value} = {out.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using PIXIE to make a shared library available as a Python C-Extension.\n",
    "\n",
    "It's easy for PIXIE to build a shared library as a Python C-Extension (importable module), just set `python_cext=True` in the compiler invocation. The output is binary module that can be imported with a \"special\" `__PIXIE__` dictionary in the module root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a compiler instance\n",
    "libfoo_compiler = PIXIECompiler(\n",
    "                                #########################\n",
    "                                # CHANGE NAME FOR C-EXT #\n",
    "                                #########################\n",
    "                                library_name='cext_foo_library', # the name for the output shared library\n",
    "                                translation_units=tus, # translation units\n",
    "                                export_configuration=export_config, # export config\n",
    "                                baseline_cpu='nocona', # The \"baseline\" CPU, this is the CPU that the library itself will target\n",
    "                                baseline_features=x86.sse3, # feature set(s) that the library will target\n",
    "                                ####################\n",
    "                                # THIS IS NOW TRUE #\n",
    "                                ####################\n",
    "                                python_cext=True, # whether the output shared library should be a C-Extension\n",
    "                                output_dir='.',) # directory in which to put the shared library once it has been created\n",
    "\n",
    "# ... and compile the shared library\n",
    "libfoo_compiler.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploring the `__PIXIE__` dictionary in a PIXIE created C-Extension.\n",
    "\n",
    "As this new PIXIE library is a C-Extension, it can just be imported like any other module. This imports the C-Extension compiled above and runs `dir` on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cext_foo_library\n",
    "dir(cext_foo_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's in the `__PIXIE__` dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(cext_foo_library.__PIXIE__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting things to note are:\n",
    "\n",
    "* The `bitcode` key, which has the LLVM bitcode used to compile the module as its value.\n",
    "* The `c_header` key, which is currently unused, but will be a place to store a C-header compatible with the bitcode/source used to compile the library.\n",
    "* The keys `is_specialized` and `specialize` which are to do with \"specialisation\" of this library (see the [next section](#5.-Host-(or-other-target)-specialisation-and-automatic-rewiring-of-the-__PIXIE__-dictionary.)).\n",
    "* The key `linkage` records linkage, e.g. `('m',)` might indicate `libm` linkage.\n",
    "* The `symbols` key which contains a symbol-table-like dictionary. It contains information in the form:\n",
    "  ```\n",
    "   <python function name> : <dictionary of signatures to details> \n",
    "  ```\n",
    "  and each `<dictionary of signatures to details>` contains a `signature` as the key which maps to a value of a  dictionary containing the following:\n",
    "  * `address` the address of function in the current process.\n",
    "  * `baseline_feature` base line feature set for this function.\n",
    "  * `cfunc`: a callable `ctypes.CFUNCTYPE` wrapper for this function.\n",
    "  * `feature_variants` (currently unused).\n",
    "  * `metadata`: a storage container for anything additional a user might want to store about this function.\n",
    "  * `module` the Python module source for this function.\n",
    "  * `source_file` the source file for this function.\n",
    "  * `symbol` the symbol name associated with this signature.\n",
    "* The `uuid` key, this is used to make the libraries \"unique\" and helps when loading \"specialisations\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same symbol that was called previously in the \"shared library\" can now be called more easily as the `ctypes` binding is already done as part of what's in the `__PIXIE__` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Walk through the `__PIXIE__` dictionary and fetch the `cfunc`\n",
    "foo_symbols = cext_foo_library.__PIXIE__['symbols']['foo']\n",
    "foo_specialisation = foo_symbols['void(double*, double*, double*)']\n",
    "cfunc = foo_specialisation['cfunc']\n",
    "\n",
    "# stage the call with the same inputs as defined previously, but a new output to make sure it works!:\n",
    "out = c_double(0)\n",
    "cfunc(*(byref(x) for x in (a, b, out)))\n",
    "print(f\"{a.value} + {b.value} = {out.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Calling functions from the `__PIXIE__` dictionary with Numba via `ctypes` and LLVM bitcode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to call the `cfunc` from above using Numba... this just uses the standard `ctypes` support that is already built in to Numba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def call_foo():\n",
    "    a = np.array([3.])\n",
    "    b = np.array([5.])\n",
    "    out = np.array([0.])\n",
    "    cfunc(a.ctypes, b.ctypes, out.ctypes)\n",
    "    print(\"result:\", out[0])\n",
    "    \n",
    "call_foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the control flow graph of the LLVM IR Numba generates is inspected, the use of `numba.dynamic.globals.<hash>` can be seen, this is the `ctypes` bound function call (it's just calling a raw address)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_foo.inspect_cfg(call_foo.signatures[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to use the `bitcode` from the PIXIE library to make the same call, but this time Numba's JIT compiler can \"see\" the function being called and optimise the call site and the body of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: this is a little involved as the PIXIE function has `double *` in its signature\n",
    "# and so Python values need to be passed-by-reference.\n",
    "\n",
    "from numba.extending import intrinsic\n",
    "from numba.core import cgutils\n",
    "from llvmlite import binding as llvm\n",
    "from llvmlite import ir as llvmir\n",
    "\n",
    "@intrinsic\n",
    "def recompiled_foo(tyctx, ty_x, ty_y):\n",
    "    assert ty_x == ty_y\n",
    "    sig = ty_x(ty_x, ty_y)\n",
    "    def codegen(cgctx, builder, sig, llargs):\n",
    "        # This loads the bitcode from the PIXIE dictionary and adds it to the code library\n",
    "        bitcode = cext_foo_library.__PIXIE__['bitcode']\n",
    "        cgctx.active_code_library.add_llvm_module(llvm.parse_bitcode(bitcode))\n",
    "        # Create an appropriate LLVM IR function signature\n",
    "        double_ptr = llvmir.DoubleType().as_pointer()\n",
    "        fnty = llvmir.FunctionType(llvmir.VoidType(), (double_ptr,) * 3)\n",
    "        # Fetch the name of the symbol associated with this function\n",
    "        foo_symbols = cext_foo_library.__PIXIE__['symbols']['foo']\n",
    "        sym_data = foo_symbols['void(double*, double*, double*)']\n",
    "        sym_name = sym_data['symbol']\n",
    "        # Create the function in the LLVM IR for this module\n",
    "        fn = cgutils.get_or_insert_function(builder.module, fnty, sym_name)\n",
    "        # Stack allocate some space and assign in the values coming from the Python call\n",
    "        x_ptr = cgutils.alloca_once_value(builder, llargs[0])\n",
    "        y_ptr = cgutils.alloca_once_value(builder, llargs[1])\n",
    "        # Allocate a stack slot for the result\n",
    "        r_ptr = cgutils.alloca_once(builder, llargs[0].type)\n",
    "        # stage the call to the function\n",
    "        builder.call(fn, (x_ptr, y_ptr, r_ptr))\n",
    "        # load and return the result as a value\n",
    "        return builder.load(r_ptr)\n",
    "    return sig, codegen\n",
    "\n",
    "@njit\n",
    "def call_bitcode_foo():\n",
    "    return recompiled_foo(1.0, 2.0)\n",
    "\n",
    "print(f\"result {call_bitcode_foo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Take a look at the control flow graph of the LLVM IR Numba generates now that the bitcode variant of the `foo` function has been used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_bitcode_foo.inspect_cfg(call_bitcode_foo.signatures[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... LLVM has managed to optimise the entire function `call_bitcode_foo` into storing the value `3.0` into Numba's `retptr` (return value) variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Host (or other target) specialisation and automatic rewiring of the `__PIXIE__` dictionary.\n",
    "\n",
    "PIXIE libraries can effectively \"recompile\" themselves. Recall that the `cext_foo_library` was originally compiled for a `nocona` series CPU targeting `SSE3` instructions, the AOT symbol calls will be running with these instructions. PIXIE libraries can trivially be re-specialised (by default to the host machine) and the C-Extension loading mechanism of the PIXIE libraries is aware of specialisations such that the `__PIXIE__` dictionary will reflect the presence of a specialised library if present. This means that Python users of C-Extension PIXIE libraries do not need to change their imports after \"specialisation\" occurs! This idea is perhaps more easily explained in code...\n",
    "\n",
    "First, dump the `foo` symbol in the original `cext_foo_library`, note the SSE3 instructions (this assumes `objdump` is present on `$PATH` and it supports `--disassemble=`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!objdump --disassemble=_Z3fooPdS_ -j .text cext_foo_library*.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the `specialize` function that is in the `__PIXIE__` dictionary, this will recompile the library to target the host CPU and create a new library named as the original but with `_pixie_specialized` appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cext_foo_library.__PIXIE__['specialize']()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the output of the above that the library has been specialised to the CPU present in the host machine. Check the `foo` symbol in the new `specialized` variant of the library, assuming the machine on which this notebook is running has instructions later than `SSE3` available the machine code in the symbol should make use of them (anything with `AVX` onwards will probably have a notable difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!objdump --disassemble=_Z3fooPdS_ -j .text cext_foo_library_pixie_specialized*.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__PIXIE__` dictionaries are \"specialisation aware\", if there's a specialised version of the C-Extension present it's automatically wired into the `__PIXIE__` dictionary during import. i.e. users do not have to change their code to use the specialised version of the library.\n",
    "\n",
    "To demonstrate... reload the module in process (do not do this in practice!), note how it picks up the specialisation on re-import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.modules.pop('cext_foo_library', None)\n",
    "import cext_foo_library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__PIXIE__` dictionary is present as before, but it's actually wired through to the specialised version (note the `is_specialized` key now has value `True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cext_foo_library.__PIXIE__['is_specialized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to demonstrate that the specialised version of the library is being reference by the imported module by loading the specialised version through `ctypes` and checking the addresses match (the link-loader invoked through the `CDLL` call will \"see\" that the specialised version is already loaded in process and just return it, which is how the addresses will be the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ctypes import cast, c_void_p\n",
    "addr = cext_foo_library.__PIXIE__['symbols']['foo']['void(double*, double*, double*)']['address']\n",
    "print(f\"Address from __PIXIE__ dictionary: {hex(addr)}\")\n",
    "specialized_name = libfoo_compiler._output_file.replace(libfoo_compiler._basename, f\"{libfoo_compiler._basename}_pixie_specialized\")\n",
    "specialized_dso = CDLL(os.path.join('.', specialized_name))\n",
    "print(f\"Address from ctypes CDLL load    : {hex(cast(specialized_dso._Z3fooPdS_, c_void_p).value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This means that any user code that calls through symbols in the `__PIXIE__` dictionary will now automatically get the specialised versions and improved performance. The package author (or packager) shipped `noconda` + `SSE3`, but the user easily specialised the library to their local hardware with no changes to their application code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Numba++'s Minimum Viable Product (MVP)\n",
    "\n",
    "What does all this mean for Numba++ (next generation Numba)? This graph shows the anticipated capabilities for Numba++'s \"minimum viable product\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numba_mvp_graph():\n",
    "    import graphviz\n",
    "    cluster_font = {'fontcolor':'#191970', 'fontname':'Arial'}\n",
    "    f = graphviz.Digraph('numba_mvp')\n",
    "    f.attr(rankdir='TB')\n",
    "    f.attr('node', shape='box', style='rounded', fontname='Arial')\n",
    "    f.attr('edge', fontname='Arial', fontsize='11')\n",
    "\n",
    "    with f.subgraph(name='cluster_C_pipeline') as c_pipe:\n",
    "        c_pipe.attr(label='C language\\nAOT pipeline', bgcolor='#aaffee60', **cluster_font)\n",
    "        c_pipe.attr('node', fillcolor='#ffffff', style='filled')\n",
    "        c_pipe.node('C/C++ library')\n",
    "        c_pipe.node('clang')\n",
    "        c_pipe.node(label='PIXIE', name='PIXIE1')\n",
    "        c_pipe.edge('C/C++ library', 'clang', label='C source')\n",
    "        c_pipe.edge('clang', 'PIXIE1', label='LLVM IR')\n",
    "\n",
    "    with f.subgraph(name='cluster_Python_AOT_pipeline') as py_pipe:\n",
    "        py_pipe.attr(label='Python language\\nAOT pipeline', bgcolor='#98fb9860', **cluster_font)\n",
    "        py_pipe.attr('node', fillcolor='#ffffff', style='filled')\n",
    "        py_pipe.node('Python')\n",
    "        py_pipe.node('Numba AOT Compiler')\n",
    "        py_pipe.node(label='PIXIE', name='PIXIE2')\n",
    "        py_pipe.edge('Python', 'Numba AOT Compiler', label='Python bytecode')\n",
    "        py_pipe.edge('Numba AOT Compiler', 'PIXIE2', label='LLVM IR')\n",
    "\n",
    "    with f.subgraph(name='cluster_Python_pipeline') as user_pipe:\n",
    "        user_pipe.attr(label='User code', bgcolor='#aa22ee60', **cluster_font)\n",
    "        user_pipe.attr('node', fillcolor='#ffffff', style='filled')\n",
    "        user_pipe.node(label='Python', name='user_python')\n",
    "\n",
    "    with f.subgraph(name='cluster_Numba_JIT') as nbjit:\n",
    "        buf = ' ' * 40\n",
    "        nbjit.attr(label=f'{buf}Numba JIT Compiler', bgcolor='#ffa50060', **cluster_font)\n",
    "        nbjit.attr('node', fillcolor='#ffffff', style='filled')\n",
    "        nbjit.node(label='LLVM cross module optimisation', name='opt')\n",
    "        nbjit.node(label='JIT pipeline', name='jit_pipeline')\n",
    "        nbjit.node(label='JIT Engine', name='jit_engine')\n",
    "        nbjit.node(label='Execution', name='exec')\n",
    "        nbjit.edge('jit_pipeline', 'opt')\n",
    "        nbjit.edge('opt', 'jit_engine', label='Optimised\\nLLVM IR')\n",
    "        nbjit.edge('jit_engine', 'exec', label='Executable\\nbinaries')\n",
    "\n",
    "    f.edge('PIXIE1', 'opt', label='PIXIE library')\n",
    "    f.edge('PIXIE2', 'opt', label='PIXIE library')\n",
    "    f.edge('user_python', 'jit_pipeline', label='Python bytecode')\n",
    "    return f\n",
    "\n",
    "numba_mvp_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "PIXIE fits into the plan/graph because:\n",
    "* PIXIE is about making it so that package authors/packagers can ship AOT deployable libraries but at the same time leave options for users to gain better performance.\n",
    "* PIXIE is indifferent to what the input source language was so long as it can be converted to LLVM bitcode.\n",
    "* Numba++ MVP is about making it possible to combine languages at the package author level and AOT/JIT compilation at the user level in a way that best suite the end application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6A. \"Blending\" input languages through AOT compiled modules. Example application, a \"custom\" solver.\n",
    "\n",
    "This example demonstrates the use of a Newton-Raphson based solver to compute the roots of the function `cos(x) + 1`. The purpose of this example is to emulate code being written in different languages and packaged by different parties and yet the user is able to make choices about how to incorporate the packaged code.\n",
    "\n",
    "1. One \"author\" writes the objective function and its derivative in C code and compiles into a PIXIE library shipped by their package.\n",
    "2. Another \"author\" writes a Newton-Raphson solver in Python and compiles into another PIXIE library shipped by their package.\n",
    "3. The libraries in 1. and 2. are used by a third author in their custom application, which is compiled with Numba's JIT compiler, and choices can be made about whether to call via bitcode or via symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compiling an objective functions module:\n",
    "\n",
    "The objective functions module comprises the C code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat objective_function.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat objective_function_derivative.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PIXIE based C compiler is needed. A quick way to obtain one is to essentially just wrap `clang` calls to get some LLVM IR and then do a compilation via the standard PIXIE tool chain. The example below creates such a compilation chain and compiles the objective function and its derivative from above into a C-extension module called `objective_functions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess, tempfile, os\n",
    "\n",
    "def tu_from_c_source(fname):\n",
    "    with tempfile.TemporaryDirectory() as build_dir:\n",
    "        outfile = os.path.join(build_dir, 'tmp.bc')\n",
    "        cmd = ('clang', '-x', 'c++', '-fPIC', '-mcmodel=small', '-emit-llvm', fname, '-o', outfile, '-c')\n",
    "        subprocess.run(cmd)\n",
    "        with open(outfile, 'rb') as f:\n",
    "            data = f.read()\n",
    "        return TranslationUnit(fname, data)\n",
    "    \n",
    "def compile_mvp_c_code():\n",
    "    src = ('objective_function.c', 'objective_function_derivative.c')\n",
    "    tus = [tu_from_c_source(s) for s in src]\n",
    "    export_config = ExportConfiguration(versioning_strategy='embed_dso')\n",
    "    export_config.add_symbol(python_name='f',\n",
    "                             symbol_name='_Z1fPdS_',\n",
    "                             signature='void(double*, double*)')\n",
    "    export_config.add_symbol(python_name='dfdx',\n",
    "                             symbol_name='_Z4dfdxPdS_',\n",
    "                             signature='void(double*, double*)')\n",
    "    compiler = PIXIECompiler(library_name='objective_functions',\n",
    "                             translation_units=tus,\n",
    "                             export_configuration=export_config,\n",
    "                             baseline_cpu='nocona',\n",
    "                             baseline_features=x86.sse3,\n",
    "                             python_cext=True,\n",
    "                             output_dir='.')\n",
    "    compiler.compile()\n",
    "    \n",
    "compile_mvp_c_code()\n",
    "\n",
    "# Check the objective functions module imports without error\n",
    "import objective_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling a root finding module:\n",
    "\n",
    "The root finding module is to be defined in Python source and compiled using a new Numba AOT compiler prototype. The `NR_root` function below implements a Newton-Raphson solver based on code derived from [here](https://github.com/numba/numba-examples/blob/cc0304f9fa75530809dc19fb7168de32b3d1a931/tutorials/nasa_apps_oct_2019/1%20-%20Numba%20basics.ipynb) under the terms of the license (see following `Details`):\n",
    "\n",
    "<details>\n",
    "\n",
    "LICENSE location:\n",
    "https://github.com/numba/numba-examples/blob/cc0304f9fa75530809dc19fb7168de32b3d1a931/LICENSE\n",
    "    \n",
    "Copy of license\n",
    "```\n",
    "BSD 2-Clause License\n",
    "\n",
    "Copyright (c) 2017, Numba\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "  list of conditions and the following disclaimer.\n",
    "\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "  this list of conditions and the following disclaimer in the documentation\n",
    "  and/or other materials provided with the distribution.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pixie_numba_compiler import aot\n",
    "from numba import types\n",
    "\n",
    "# A function type that takes a value of double type as an argument and returns a value of double type.\n",
    "fn_type = types.FunctionType(types.double(types.double))\n",
    "\n",
    "# Say hello to a new Numba AOT compiler!\n",
    "@aot((types.double(fn_type, fn_type, types.double, types.double, types.intp)),)\n",
    "def NR_root(f, dfdx, x0, eps, max_it):\n",
    "    converged = False\n",
    "    for i in range(max_it):\n",
    "        y = f(x0)\n",
    "        yp = dfdx(x0)\n",
    "        if abs(yp) < eps:\n",
    "            break\n",
    "        x1 = x0 - y / yp\n",
    "        if abs(x1 - x0) <= eps:\n",
    "            converged = True\n",
    "            break\n",
    "        x0 = x1\n",
    "    if converged:\n",
    "        return x1\n",
    "    else:\n",
    "        raise RuntimeError(\"Solution did not converge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile the `@aot` declared Python function using some Numba derived bindings around PIXIE tools so as to create a C-Extension module called `optimiser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pixie_numba_compiler import TranslationUnit, Library\n",
    "\n",
    "# Create a translation unit\n",
    "translation_unit = TranslationUnit()\n",
    "# Add the NR_root function to it\n",
    "translation_unit.add(NR_root)\n",
    "# Create library instance\n",
    "opt_lib = Library('optimiser', (translation_unit,), outdir='.')\n",
    "# Compile\n",
    "opt_lib.compile()\n",
    "\n",
    "# Check it imports\n",
    "import optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Custom user code to achieve \"blended compilation\":\n",
    "\n",
    "This defines the custom user code that will consume the modules that have been AOT compiled from the multiple source languages. Binding to code where C is the input language is currently a little more involved but can be achieved through the use of a Numba `@intrinsic`, the objective functions are bound in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_objective_func_callsite(pixie_lib, pysym, pixie_sig):\n",
    "    @intrinsic\n",
    "    def bind_call(tyctx, ty_x):\n",
    "        sig = ty_x(ty_x)\n",
    "        \n",
    "        def codegen(cgctx, builder, sig, llargs):\n",
    "            # This loads the bitcode from the PIXIE dictionary and adds it to the code library\n",
    "            bitcode = pixie_lib.__PIXIE__['bitcode']\n",
    "            cgctx.active_code_library.add_llvm_module(llvm.parse_bitcode(bitcode))\n",
    "            # Create an appropriate LLVM IR function signature\n",
    "            double_ptr = llvmir.DoubleType().as_pointer()\n",
    "            fnty = llvmir.FunctionType(llvmir.VoidType(), (double_ptr,) * 2)\n",
    "            # Fetch the name of the symbol associated with this function\n",
    "            fn_symbols = pixie_lib.__PIXIE__['symbols'][pysym]\n",
    "            sym_name = fn_symbols[pixie_sig]['symbol']\n",
    "            # Create the function in the LLVM IR for this module\n",
    "            fn = cgutils.get_or_insert_function(builder.module, fnty, sym_name)\n",
    "            # Stack allocate some space and assign in the values coming from the Python call\n",
    "            x_ptr = cgutils.alloca_once_value(builder, llargs[0])\n",
    "            # Allocate a stack slot for the result\n",
    "            r_ptr = cgutils.alloca_once(builder, llargs[0].type)\n",
    "            # stage the call to the function\n",
    "            builder.call(fn, (x_ptr, r_ptr))\n",
    "            # load and return the result as a value\n",
    "            return builder.load(r_ptr)\n",
    "        \n",
    "        return sig, codegen\n",
    "    \n",
    "    # make sure the functions can be used as first-class function types\n",
    "    # by wrapping them in a `@njit` function. This function can be inlined\n",
    "    # and doesn't need to be callable from CPython.\n",
    "    @njit(forceinline=True, no_cpython_wrapper=True)\n",
    "    def trampoline(x):\n",
    "        return bind_call(x)\n",
    "\n",
    "    return trampoline\n",
    "\n",
    "# Create the binding instances\n",
    "import objective_functions\n",
    "f = gen_objective_func_callsite(objective_functions, 'f', 'void(double*, double*)')\n",
    "dfdx = gen_objective_func_callsite(objective_functions, 'dfdx', 'void(double*, double*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimiser code that was compiled via the Numba AOT prototype compiler can be more easily accessed as the compiler stored some meta-data into the `__PIXIE__` dictionary about the call site. A `pixie_converter` function uses this meta-data and makes the Numba AOT compiled functions in the `optimiser` module available for calling inside Numba compiled code (and also in the interpreter, they are `@numba.njit` wrapped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optimiser\n",
    "from numba_helpers import pixie_converter\n",
    "# Convert the PIXIE module functions into ones that Numba can call\n",
    "numba_optimiser = pixie_converter(optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exported symbols appear as a `namedtuple` with members `jit` and `aot` so as to let the user decide how to stage the call, `.jit` for call via `bitcode` and `.aot` for call via symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numba_optimiser.NR_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, call the `NR_root` function to do root finding for functions `f` and `dfdx` originally from the C code. The `.jit` variant will use the bitcode from the PIXIE library and take part in optimisation at compile time. The `.aot` variant will use the symbol from the PIXIE library and not take part in optimisation at compile time as it is an opaque call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def specialized_find_roots(eps=1e-7, max_it=50):\n",
    "    # call jit version\n",
    "    result_jit = numba_optimiser.NR_root.jit(f, dfdx, 0.5, eps, max_it)\n",
    "    # call aot version, but vary input to get a noticably different output\n",
    "    result_aot = numba_optimiser.NR_root.aot(f, dfdx, 0.8, 1e-3, max_it) \n",
    "    return result_jit, result_aot\n",
    "\n",
    "# Should be ~pi.\n",
    "print(specialized_find_roots())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes an example of source mixing languages for use in Numba via PIXIE. Unfortunately, due to a current limitation in Numba's handling of first-class function types, there's no real performance gain when using the `.jit` version in comparison to the `.aot` version. However, the next example aims to demonstrate such an effect.\n",
    "\n",
    "### 6B. \"Blending\" performance through AOT compiled modules. Example application, a DAXPY-like function call.\n",
    "\n",
    "The following `@aot` compiled function defines a DAXPY-like (see BLAS libraries) call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@aot(types.double[::1](types.double[::1], types.double, types.double),)\n",
    "def daxpy(a, x, y):\n",
    "    for i in range(len(a)):\n",
    "        a[i] = a[i] * x + y\n",
    "    return a\n",
    "\n",
    "translation_unit = TranslationUnit()\n",
    "translation_unit.add(daxpy)\n",
    "daxpy_lib = Library('daxpy', (translation_unit,), outdir='.')\n",
    "daxpy_lib.compile()\n",
    "\n",
    "# check it imports\n",
    "import daxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes only, these functions do a large iteration count loop over operations on a small vector, namely a `DAXPY` call and then a reduction via `sum()`. The `.aot` variant will end up with a call to a symbol in the loop that will prevent a variety of optimisations as well as incurring the cost of a call. The `.jit` variant will have the `DAXPY` call take part in the loop body optimisation and should provide a faster executing loop. The `pixie_converter` is used again to easily let the functions in the PIXIE library be called by Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numba_daxpy = pixie_converter(daxpy)\n",
    "\n",
    "n = 100000\n",
    "\n",
    "# define a NumPy variant to use to check the result is correct.\n",
    "def call_numpy(a, x, y):\n",
    "    acc = 0.\n",
    "    for i in range(n):\n",
    "        a = a * x + y\n",
    "        acc += a.sum()\n",
    "    return acc\n",
    "\n",
    "# define a Numba version that calls the `.aot` version.\n",
    "@njit\n",
    "def call_aot(a, x, y):\n",
    "    acc = 0.\n",
    "    for i in range(n):\n",
    "        numba_daxpy.daxpy.aot(a, x, y) # call via symbol\n",
    "        acc += a.sum()\n",
    "    return acc\n",
    "\n",
    "# define a Numba version that calls the `.jit` version.\n",
    "@njit\n",
    "def call_jit(a, x, y):\n",
    "    acc = 0.\n",
    "    for i in range(n):\n",
    "        numba_daxpy.daxpy.jit(a, x, y) # call via bitcode, should in-line and be optimised\n",
    "        acc += a.sum()\n",
    "    return acc\n",
    "\n",
    "# Generates inputs (a, x, y)\n",
    "def gen_input(n):\n",
    "    return np.arange(1, n + 1).astype(np.float64), .1, .2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that the implementations all produce the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check():\n",
    "    n = 10\n",
    "    np_args = gen_input(n)\n",
    "    expected = call_numpy(*np_args)\n",
    "    aot_args = gen_input(n)\n",
    "    aot_result = call_aot(*aot_args)\n",
    "    jit_args = gen_input(n)\n",
    "    jit_result = call_jit(*jit_args)\n",
    "    \n",
    "    np.testing.assert_allclose(expected, aot_result)\n",
    "    np.testing.assert_allclose(expected, jit_result)\n",
    "    \n",
    "# check the results!\n",
    "check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a deliberately short \"internal\" vector size such that the call via symbol is disproportionately expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "short_vector_len = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the performance of the implementations... (approximate scale of performance results are noted in brackets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = gen_input(short_vector_len)\n",
    "%timeit call_numpy(*args) # (typically \"X\" time units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = gen_input(short_vector_len)\n",
    "%timeit call_aot(*args) # (typically \"X/100\" time units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = gen_input(short_vector_len)\n",
    "%timeit call_jit(*args) # (typically \"X/1000\" time units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This concludes the demonstration of the current state of the PIXIE project.\n",
    "\n",
    "Feedback is welcomed, please do open issues or post on Numba's discourse forum!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
